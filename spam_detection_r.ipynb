{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.3.1"
    },
    "colab": {
      "name": "spam_detection_r.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudio-bon/spam-detection-r/blob/main/spam_detection_r.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1FShEQFxJto"
      },
      "source": [
        "# Spam Detection\n",
        "In this project it will be performed a text classification task on a dataset composed of a textual field that contain a message and a related label which indicate wether the message it either a spam or a ham (not a spam).<br>\n",
        "The classfication will be performed through the deployment of two machine learning models. An evaluation of the confidence interval and a comparison between the two will also be done.<br>\n",
        "Moreover it will also be attempted an LSA transformation of the features' space and a successive reassessment of the previously used models with the newly created features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgMicbTlgwMk",
        "outputId": "c8a7e4cb-7834-4bbb-f540-cee05c363a31"
      },
      "source": [
        "if(!require(\"magrittr\"))\n",
        "    install.packages(\"magrittr\")\n",
        "library(magrittr)\n",
        "\n",
        "if(!require(\"tokenizers\"))\n",
        "    install.packages(\"tokenizers\")\n",
        "library(tokenizers)\n",
        "\n",
        "if(!require(\"data.table\"))\n",
        "    install.packages(\"data.table\")\n",
        "library(data.table)\n",
        "\n",
        "if(!require(\"text2vec\"))\n",
        "    install.packages(\"text2vec\")\n",
        "library(text2vec)\n",
        "\n",
        "if(!require(\"qdap\"))\n",
        "    install.packages(\"qdap\")\n",
        "library(qdap)\n",
        "\n",
        "if(!require(\"class\"))\n",
        "    install.packages(\"class\")\n",
        "library(class)\n",
        "\n",
        "if(!require(\"MLmetrics\"))\n",
        "    install.packages(\"MLmetrics\")\n",
        "library(MLmetrics)\n",
        "\n",
        "if(!require(\"glmnet\"))\n",
        "    install.packages(\"glmnet\")\n",
        "library(glmnet)\n",
        "\n",
        "if(!require(\"stats\"))\n",
        "    install.packages(\"stats\")\n",
        "library(stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading required package: magrittr\n",
            "\n",
            "Loading required package: tokenizers\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘tokenizers’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘SnowballC’\n",
            "\n",
            "\n",
            "Loading required package: data.table\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘data.table’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: text2vec\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘text2vec’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘float’, ‘RhpcBLASctl’, ‘RcppArmadillo’, ‘rsparse’, ‘mlapi’, ‘lgr’\n",
            "\n",
            "\n",
            "Loading required package: qdap\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘qdap’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘openNLPdata’, ‘rJava’, ‘bitops’, ‘plyr’, ‘slam’, ‘qdapDictionaries’, ‘qdapRegex’, ‘qdapTools’, ‘chron’, ‘gender’, ‘gridExtra’, ‘igraph’, ‘NLP’, ‘openNLP’, ‘openxlsx’, ‘plotrix’, ‘RCurl’, ‘reshape2’, ‘stringdist’, ‘tm’, ‘venneuler’, ‘wordcloud’, ‘XML’\n",
            "\n",
            "\n",
            "Loading required package: qdapDictionaries\n",
            "\n",
            "Loading required package: qdapRegex\n",
            "\n",
            "Loading required package: qdapTools\n",
            "\n",
            "\n",
            "Attaching package: ‘qdapTools’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:data.table’:\n",
            "\n",
            "    shift\n",
            "\n",
            "\n",
            "Loading required package: RColorBrewer\n",
            "\n",
            "\n",
            "Attaching package: ‘qdap’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    Filter, proportions\n",
            "\n",
            "\n",
            "Loading required package: class\n",
            "\n",
            "\n",
            "Attaching package: ‘class’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:qdap’:\n",
            "\n",
            "    condense\n",
            "\n",
            "\n",
            "Loading required package: MLmetrics\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘MLmetrics’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘gtools’, ‘caTools’, ‘gplots’, ‘ROCR’\n",
            "\n",
            "\n",
            "\n",
            "Attaching package: ‘MLmetrics’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:base’:\n",
            "\n",
            "    Recall\n",
            "\n",
            "\n",
            "Loading required package: glmnet\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘glmnet’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘iterators’, ‘foreach’, ‘shape’\n",
            "\n",
            "\n",
            "Loading required package: Matrix\n",
            "\n",
            "\n",
            "Attaching package: ‘Matrix’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:qdap’:\n",
            "\n",
            "    %&%\n",
            "\n",
            "\n",
            "Loaded glmnet 4.1-1\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LegCu2gYBny-"
      },
      "source": [
        "# Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa5sLKzKztUN"
      },
      "source": [
        "### Download\n",
        "Download and extraction of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh0JlB_g6eAv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef1970b2-4601-488a-d50a-09e565079447"
      },
      "source": [
        "download.file(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\",\n",
        "              \"smsspamcollection.zip\")\n",
        "unzip(\"smsspamcollection.zip\")\n",
        "file.remove(\"readme\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] TRUE"
            ],
            "text/latex": "TRUE",
            "text/markdown": "TRUE",
            "text/html": [
              "TRUE"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-aT6TeKzvjZ"
      },
      "source": [
        "### Load on Table\n",
        "The data will be loaded on a `data.table` structure type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJP9NkSOJ3vH"
      },
      "source": [
        "table <- fread(\"SMSSpamCollection\" ,sep=\"\\t\", header=FALSE, col.names=c(\"class\",\"text\"), quote=\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQl8KAh1vt9b"
      },
      "source": [
        "Dataset exploration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muWckMye-AoY"
      },
      "source": [
        "i<-0\n",
        "while (i<5570) {\n",
        "    print(i)\n",
        "    print(table[i,])\n",
        "    i<-i+1\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynbWIbHmBwmH"
      },
      "source": [
        "# Text Preprocessing\n",
        "From data exploration it can be observed that many spam messages shares some common features such as: presence of links, emails, telephone numbers and money quantities.<br>\n",
        "In order for the models to capture this pattern it should be attempted a normalization of the fetures described above trying to group them all using the same tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bw9NeJpB0D3"
      },
      "source": [
        "lower <- function(text) tolower(text)\n",
        "tokenize <- function(text) tokenize_words(text)\n",
        "#substitute link as \"<LINK>\"\n",
        "link_sub <- function(text) gsub( \"(https?://)?(www\\\\.)?((\\\\w|-)+\\\\.\\\\s?){1,2}(co\\\\.\\\\s?)?(com|net|biz|uk|org|tv|ac)([A-Za-z0-9?&/!\\\\-\\\\=]*)\", \" <LINK>\", text)\n",
        "#substitute emails with \"<EMAIL>\"\n",
        "email_sub <- function(text) gsub(\"[A-Za-z0-9.]+@[A-Za-z0-9]+\\\\.((co|uk)\\\\.)?(com|net|biz|uk|org|tv|ac)\", \"<EMAIL>\", text)\n",
        "#money quantity (e.g. £100 or £1.5) to \"<MONEY>\"\n",
        "money_sub <- function(text) gsub(\"(£[0-9]+((\\\\.|,)[0-9]+)?)|([0-9]+(p/min|ppm|p\\\\sper\\\\sminute))\", \"<MONEY>\", text)\n",
        "#long number (generally phone numbers)\n",
        "long_number_sub <- function(text) gsub(\"(\\\\+?\\\\d{5,})|(([0-9]{3,}-)+[0-9]{3,})|(([0-9]{3,}\\\\s)+[0-9]{3,})\", \"<LONGNUM>\", text)\n",
        "#\\u0092\n",
        "apostrophe_code_sub <- function(text) gsub(\"\\\\\\\\u0092\", \"'\", text)\n",
        "#ukn char code\n",
        "ukn_code_sub <- function (text) gsub(\"&lt;#&gt;\", \"<UKNCODE>\", text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBlsiaQ5IVXO"
      },
      "source": [
        "All the defined preprocessing function will be chained in order to form a preprocessing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MpPy511ERK7"
      },
      "source": [
        "preprocess_text <- function(text) {\n",
        "    text %>%\n",
        "        lower() %>%\n",
        "        link_sub() %>%\n",
        "        email_sub() %>%\n",
        "        money_sub() %>%\n",
        "        long_number_sub() %>%\n",
        "        apostrophe_code_sub() %>%\n",
        "        ukn_code_sub() %>%\n",
        "        replace_contraction()\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRlZWWmzwWra"
      },
      "source": [
        "Show the result of the preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az0a0OOBgHMg"
      },
      "source": [
        "preprocess_text(table$text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC-VtyPsdrRz"
      },
      "source": [
        "# Split the Dataset\n",
        "The dataset is splitted in training and test set in a proportion of 75 - 25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpFy8qoidrY5"
      },
      "source": [
        "smp_size <- floor(0.75 * nrow(table))\n",
        "train_idx <- sample(seq_len(nrow(table)), size = smp_size)\n",
        "train <- table[train_idx, ]\n",
        "test <- table[-train_idx, ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP2hgD_0gs63"
      },
      "source": [
        "# Feature Generation\n",
        "The feature used to train the models is TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H29p20nfNNG"
      },
      "source": [
        "it_train = itoken(train$text,\n",
        "            preprocessor = preprocess_text,\n",
        "            tokenizer = word_tokenizer,\n",
        "            progressbar = FALSE)\n",
        "\n",
        "vocab = create_vocabulary(it_train)\n",
        "vectorizer = vocab_vectorizer(vocab)\n",
        "dtm_train = create_dtm(it_train, vectorizer)\n",
        "\n",
        "\n",
        "tfidf = TfIdf$new()\n",
        "# fit model to train data and transform train data with fitted model\n",
        "dtm_train_tfidf = fit_transform(dtm_train, tfidf)\n",
        "\n",
        "# apply pre-trained tf-idf transformation to test data\n",
        "it_test = itoken(test$text,\n",
        "            preprocessor = preprocess_text,\n",
        "            tokenizer = word_tokenizer,\n",
        "            progressbar = FALSE)\n",
        "\n",
        "dtm_test = create_dtm(it_test, vectorizer)\n",
        "dtm_test_tfidf = transform(dtm_test, tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJlDMQGIBSOW"
      },
      "source": [
        "# Classification\n",
        "In this section two models will be adopted in the attempt to perform a classification task in order to discern ham vs. spam messages.<br>\n",
        "The models that will be used are KNN and Linear Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkFpcNxropPD"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx_wJeDYNAZB"
      },
      "source": [
        "Since KNN has no training phase it can be immediately performed the prediction on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ1W7I_IBRY6"
      },
      "source": [
        "#time >20 minutes\n",
        "knn_preds <- knn(train = dtm_train_tfidf, test = dtm_test_tfidf, cl = train$class, k=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUmF1s-4MBO2"
      },
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "aI5V2OXDkAhD",
        "outputId": "3c5a077b-9565-44a8-bd85-d5370ce1105a"
      },
      "source": [
        "cat(\"Confusion Matrix:\")\n",
        "ConfusionDF(y_pred = knn_preds, y_true = test$class)\n",
        "cat(\"\\nF1 score:\")\n",
        "F1_Score(y_pred = knn_preds, y_true = test$class)\n",
        "cat(\"\\nAccuracy:\")\n",
        "Accuracy(y_pred = knn_preds, y_true = test$class)\n",
        "cat(\"\\nPrecision:\")\n",
        "Precision(y_pred = knn_preds, y_true = test$class)\n",
        "cat(\"\\nRecall:\")\n",
        "Recall(y_pred = knn_preds, y_true = test$class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  y_true y_pred Freq\n",
              "1 ham    ham    1212\n",
              "2 spam   ham     124\n",
              "3 ham    spam      1\n",
              "4 spam   spam     57"
            ],
            "text/latex": "A data.frame: 4 × 3\n\\begin{tabular}{lll}\n y\\_true & y\\_pred & Freq\\\\\n <chr> & <chr> & <int>\\\\\n\\hline\n\t ham  & ham  & 1212\\\\\n\t spam & ham  &  124\\\\\n\t ham  & spam &    1\\\\\n\t spam & spam &   57\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 4 × 3\n\n| y_true &lt;chr&gt; | y_pred &lt;chr&gt; | Freq &lt;int&gt; |\n|---|---|---|\n| ham  | ham  | 1212 |\n| spam | ham  |  124 |\n| ham  | spam |    1 |\n| spam | spam |   57 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 4 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>y_true</th><th scope=col>y_pred</th><th scope=col>Freq</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>ham </td><td>ham </td><td>1212</td></tr>\n",
              "\t<tr><td>spam</td><td>ham </td><td> 124</td></tr>\n",
              "\t<tr><td>ham </td><td>spam</td><td>   1</td></tr>\n",
              "\t<tr><td>spam</td><td>spam</td><td>  57</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "F1 score:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9509612"
            ],
            "text/latex": "0.950961161239702",
            "text/markdown": "0.950961161239702",
            "text/html": [
              "0.950961161239702"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.91033"
            ],
            "text/latex": "0.910329985652798",
            "text/markdown": "0.910329985652798",
            "text/html": [
              "0.910329985652798"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Precision:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9071856"
            ],
            "text/latex": "0.907185628742515",
            "text/markdown": "0.907185628742515",
            "text/html": [
              "0.907185628742515"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Recall:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9991756"
            ],
            "text/latex": "0.999175597691674",
            "text/markdown": "0.999175597691674",
            "text/html": [
              "0.999175597691674"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrFroPgSfh7y"
      },
      "source": [
        "#### Confidence\n",
        "Let's start by definind the functions that will compute the confidence interval of the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQdFbZTSjkkk"
      },
      "source": [
        "compute_z <- function(confidence) {\n",
        "    alpha <- 1-confidence\n",
        "    qnorm(1-(alpha/2))\n",
        "}\n",
        "compute_pmax <- function(N, acc, Z) (2*N*acc + Z^2 + Z*sqrt(Z^2 + 4*N*acc - 4*N*acc^2))/(2*(N + Z^2))\n",
        "compute_pmin <- function(N, acc, Z) (2*N*acc + Z^2 - Z*sqrt(Z^2 + 4*N*acc - 4*N*acc^2))/(2*(N + Z^2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buoumlo2jk_m"
      },
      "source": [
        "get_num_pos <- function(y_pred, y_true) {\n",
        "    confusion_mat <- ConfusionDF(y_pred = y_pred, y_true = y_true)\n",
        "    pos_matrix <- subset(confusion_mat, y_true == y_pred)\n",
        "    pos <- sum(pos_matrix$Freq)\n",
        "}\n",
        "\n",
        "get_confidence_interval <- function(confidence, y_pred, y_true) {\n",
        "    pos <- get_num_pos(y_pred = y_pred, y_true = y_true)\n",
        "    n_trials <- length(y_true)\n",
        "    acc <- pos/n_trials\n",
        "\n",
        "    #Compute Z\n",
        "    Z <- compute_z(confidence = confidence)\n",
        "\n",
        "    #Compute p-value\n",
        "    pmin <- compute_pmin(N = n_trials, acc = acc, Z = Z)\n",
        "    pmax <- compute_pmax(N = n_trials, acc = acc, Z = Z)\n",
        "\n",
        "    list(\"min\" = pmin, \"max\" = pmax)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVPUOXFZMHGz"
      },
      "source": [
        "Let's compute the confidence interval of the model's prediction with a confidence level of $0.95$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX3kipr5i1Tl",
        "outputId": "cdf9f9e0-6d4f-4f43-c717-c82f85d54bca"
      },
      "source": [
        "p_knn <- get_confidence_interval(confidence = 0.95, y_pred = knn_preds, y_true = test$class)\n",
        "cat(\"Confidence interval: \")\n",
        "cat(\"(\",p_knn$min,\", \",p_knn$max,\")\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confidence interval: ( 0.8941824 ,  0.9242223 )"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pwfTdrlotHk"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0S36rSJb02"
      },
      "source": [
        "Train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-14CN2hkwzpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f2e0e1-a4a5-4708-b711-308f86b6877d"
      },
      "source": [
        "binomial_model <- cv.glmnet(x = dtm_train_tfidf, y = train$class, family = \"binomial\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "“from glmnet Fortran code (error code -62); Convergence for 62th lambda value not reached after maxit=100000 iterations; solutions for larger lambdas returned”\n",
            "Warning message:\n",
            "“from glmnet Fortran code (error code -61); Convergence for 61th lambda value not reached after maxit=100000 iterations; solutions for larger lambdas returned”\n",
            "Warning message:\n",
            "“from glmnet Fortran code (error code -60); Convergence for 60th lambda value not reached after maxit=100000 iterations; solutions for larger lambdas returned”\n",
            "Warning message:\n",
            "“from glmnet Fortran code (error code -60); Convergence for 60th lambda value not reached after maxit=100000 iterations; solutions for larger lambdas returned”\n",
            "Warning message:\n",
            "“from glmnet Fortran code (error code -61); Convergence for 61th lambda value not reached after maxit=100000 iterations; solutions for larger lambdas returned”\n",
            "Warning message:\n",
            "“from glmnet Fortran code (error code -61); Convergence for 61th lambda value not reached after maxit=100000 iterations; solutions for larger lambdas returned”\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq_3CiB-Jhu_"
      },
      "source": [
        "Use the trained model to predict on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euaqmr4r53Gj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "807ca92a-7b76-4d9c-e688-aa0a91408961"
      },
      "source": [
        "binomial_probabilities <- predict(binomial_model, newx = dtm_test_tfidf, type = \"response\")\n",
        "head(binomial_probabilities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  1         \n",
              "1 0.03391054\n",
              "2 0.03391054\n",
              "3 0.84534710\n",
              "4 0.03391054\n",
              "5 0.32865097\n",
              "6 0.03391054"
            ],
            "text/latex": "A matrix: 6 × 1 of type dbl\n\\begin{tabular}{r|l}\n  & 1\\\\\n\\hline\n\t1 & 0.03391054\\\\\n\t2 & 0.03391054\\\\\n\t3 & 0.84534710\\\\\n\t4 & 0.03391054\\\\\n\t5 & 0.32865097\\\\\n\t6 & 0.03391054\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA matrix: 6 × 1 of type dbl\n\n| <!--/--> | 1 |\n|---|---|\n| 1 | 0.03391054 |\n| 2 | 0.03391054 |\n| 3 | 0.84534710 |\n| 4 | 0.03391054 |\n| 5 | 0.32865097 |\n| 6 | 0.03391054 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 6 × 1 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>1</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>0.03391054</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>0.03391054</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>0.84534710</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>0.03391054</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>0.32865097</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>0.03391054</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKUtAtuRJEw5"
      },
      "source": [
        "Cast probabilities to class predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap_qDgnhjQor"
      },
      "source": [
        "threshold <- function(x) as.integer(x >=0.5)\n",
        "idx_to_class <- function(x) if (x==0) \"ham\" else \"spam\"\n",
        "p2c <- function(x) {x %>% threshold %>% idx_to_class}\n",
        "preds_to_class <- function(preds) sapply(preds, p2c)\n",
        "\n",
        "binomial_preds <- preds_to_class(binomial_probabilities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyd6T8CEJsFU"
      },
      "source": [
        "Show measures:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "eCGh_jSCmALg",
        "outputId": "df8ce7af-f446-45a2-a1c5-615fde544f3a"
      },
      "source": [
        "cat(\"Confusion Matrix:\")\n",
        "ConfusionDF(y_pred = binomial_preds, y_true = test$class)\n",
        "cat(\"\\nF1 score:\")\n",
        "F1_Score(y_pred = binomial_preds, y_true = test$class)\n",
        "cat(\"\\nAccuracy:\")\n",
        "Accuracy(y_pred = binomial_preds, y_true = test$class)\n",
        "cat(\"\\nPrecision:\")\n",
        "Precision(y_pred = binomial_preds, y_true = test$class)\n",
        "cat(\"\\nRecall:\")\n",
        "Recall(y_pred = binomial_preds, y_true = test$class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  y_true y_pred Freq\n",
              "1 ham    ham    1209\n",
              "2 spam   ham      36\n",
              "3 ham    spam      4\n",
              "4 spam   spam    145"
            ],
            "text/latex": "A data.frame: 4 × 3\n\\begin{tabular}{lll}\n y\\_true & y\\_pred & Freq\\\\\n <chr> & <chr> & <int>\\\\\n\\hline\n\t ham  & ham  & 1209\\\\\n\t spam & ham  &   36\\\\\n\t ham  & spam &    4\\\\\n\t spam & spam &  145\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 4 × 3\n\n| y_true &lt;chr&gt; | y_pred &lt;chr&gt; | Freq &lt;int&gt; |\n|---|---|---|\n| ham  | ham  | 1209 |\n| spam | ham  |   36 |\n| ham  | spam |    4 |\n| spam | spam |  145 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 4 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>y_true</th><th scope=col>y_pred</th><th scope=col>Freq</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>ham </td><td>ham </td><td>1209</td></tr>\n",
              "\t<tr><td>spam</td><td>ham </td><td>  36</td></tr>\n",
              "\t<tr><td>ham </td><td>spam</td><td>   4</td></tr>\n",
              "\t<tr><td>spam</td><td>spam</td><td> 145</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "F1 score:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9837266"
            ],
            "text/latex": "0.983726606997559",
            "text/markdown": "0.983726606997559",
            "text/html": [
              "0.983726606997559"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9713056"
            ],
            "text/latex": "0.971305595408895",
            "text/markdown": "0.971305595408895",
            "text/html": [
              "0.971305595408895"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Precision:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9710843"
            ],
            "text/latex": "0.971084337349398",
            "text/markdown": "0.971084337349398",
            "text/html": [
              "0.971084337349398"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Recall:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9967024"
            ],
            "text/latex": "0.996702390766694",
            "text/markdown": "0.996702390766694",
            "text/html": [
              "0.996702390766694"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9bAfsaafs6S"
      },
      "source": [
        "#### Confidence\n",
        "Confidence interval for a confidence level of $0.95$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wsZDFW4iT-X",
        "outputId": "979c1591-0e73-4208-8695-dcbe31c7ab31"
      },
      "source": [
        "p_bin <- get_confidence_interval(confidence = 0.95, y_pred = binomial_preds, y_true = test$class)\n",
        "cat(\"Confidence interval: \")\n",
        "cat(\"(\",p_bin$min,\", \",p_bin$max,\")\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confidence interval: ( 0.9611633 ,  0.9788575 )"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbigbDSbBsj1"
      },
      "source": [
        "### Comparing Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf8klnEQPZD9"
      },
      "source": [
        "Functions to compute variance $\\hat\\sigma_i$ and error rates $e_i$ of the single models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnJGgYCbHWiD"
      },
      "source": [
        "get_e <- function(N, N_pos) (N - N_pos)/N\n",
        "get_var <- function(N, e) (e*(1-e))/N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dwn85ipQCi7"
      },
      "source": [
        "Functions to computes the difference of the models' errors $d$ and the sum of the models' variances $\\hat\\sigma_t$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3r2YY59qCk4"
      },
      "source": [
        "get_d <- function(e_1, e_2) abs(e_1 - e_2)\n",
        "get_var_t <- function(n_trials, e_1, e_2) {\n",
        "    var_1 <- get_var(n_trials, e_1)\n",
        "    var_2 <- get_var(n_trials, e_2)\n",
        "    var_1 + var_2\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3TrAygEQrGi"
      },
      "source": [
        "Function to compute the error interval of the two models $d_t$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6FoO5QtQrNV"
      },
      "source": [
        "get_dt <- function(Z, d, var_t) {\n",
        "    list(\"max\" = d + Z*sqrt(var_t), \"min\" = d - Z*sqrt(var_t))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlCNYHAXQ2C-"
      },
      "source": [
        "Now let's compare the KNN and the Linear Regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uiVXXR9t0-C"
      },
      "source": [
        "n_trials <- length(test$class)\n",
        "pos_knn <- get_num_pos(knn_preds, test$class)\n",
        "pos_bin <- get_num_pos(binomial_preds, test$class)\n",
        "\n",
        "e_knn <- get_e(n_trials, pos_knn)\n",
        "e_bin <- get_e(n_trials, pos_bin)\n",
        "\n",
        "d <- get_d(e_knn, e_bin)\n",
        "var_t <- get_var_t(n_trials, e_knn, e_bin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au7ZkHYio0Cy",
        "outputId": "3150cbde-7f6e-4ee8-d84a-73ff00c3c8ac"
      },
      "source": [
        "Z <- compute_z(confidence = 0.95)\n",
        "dt <- get_dt(Z, d, var_t)\n",
        "\n",
        "cat(\"Confidence interval: \")\n",
        "cat(\"(\",dt$min,\", \",dt$max,\")\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confidence interval: ( 0.04360463 ,  0.07834659 )"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-3BX0KyFUym"
      },
      "source": [
        "Since 0 is not present in the interval, for confidence value of 0.95 the difference between the two models can be said to be significant.<br>\n",
        "In order to find the confidence value such that the difference between the two models is negligible it's required to find the value of $Z_{\\alpha/2}$ such that $Z_{\\alpha/2}\\hat{\\sigma}_t\\geq d\\Rightarrow Z_{\\alpha/2}\\geq \\frac{d}{\\hat{\\sigma}_t}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gwNCO88IQ32"
      },
      "source": [
        "compute_confidence <- function(Z) 1-2*(1-pnorm(Z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK-g_lWj7b-6",
        "outputId": "4b0a6a32-f6e4-4f06-fd3e-57087323c6c9"
      },
      "source": [
        "min_z = d/sqrt(var_t)\n",
        "cat(\"Z =\",min_z,\"\\n\")\n",
        "\n",
        "negligible_confidence <- compute_confidence(Z = min_z)\n",
        "cat(\"Negligible confidence level:\",negligible_confidence,\"\\n\")\n",
        "\n",
        "dt_negl <- get_dt(min_z, d, var_t)\n",
        "cat(\"Confidence interval: \")\n",
        "cat(\"(\",dt_negl$min,\", \",dt_negl$max,\")\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z = 6.879863 \n",
            "Negligible confidence level: 1 \n",
            "Confidence interval: ( 0 ,  0.1219512 )"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekRhO7t6EBeh"
      },
      "source": [
        "It can indeed be seen that for $Z_{\\alpha /2}=8.80$, $0$ is included in the confidence interval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jdqnXQ-GoRZ"
      },
      "source": [
        "# LSA\n",
        "The feature space created by the TF-IDF procedure is very large (with high dimensionality) and sparse as well. The LSA procedure is able to fix these two problems by creating a smaller dense space with the addition of bringing out the latent relationship of the TF-IDF features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHSo-skqTAX-"
      },
      "source": [
        "Since applying LSA imply also reducing the feature space it would be helpful to know the dimension of the starting feature space (the one generated by the TF-IDF procedure)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "g0Z0XxQlR7Pq",
        "outputId": "35c0432e-73f7-4d08-d11d-701823f2c03b"
      },
      "source": [
        "dim(vocab)[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 7923"
            ],
            "text/latex": "7923",
            "text/markdown": "7923",
            "text/html": [
              "7923"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMaXwx3nTmB3"
      },
      "source": [
        "Let's define a LSA transformation that holds 300 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWSElULSGoXa",
        "outputId": "2c0cc0ad-396e-40d8-bd62-2f7a6302d987"
      },
      "source": [
        "lsa_m = LatentSemanticAnalysis$new(300)\n",
        "train_lsa = lsa_m$fit_transform(dtm_train_tfidf)\n",
        "test_lsa = lsa_m$transform(dtm_test_tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO  [12:57:32.326] soft_als: iter 001, frobenious norm change 11.730 loss NA  \n",
            "INFO  [12:57:33.292] soft_als: iter 002, frobenious norm change 0.498 loss NA  \n",
            "INFO  [12:57:34.332] soft_als: iter 003, frobenious norm change 0.065 loss NA  \n",
            "INFO  [12:57:35.325] soft_als: iter 004, frobenious norm change 0.020 loss NA  \n",
            "INFO  [12:57:36.243] soft_als: iter 005, frobenious norm change 0.009 loss NA  \n",
            "INFO  [12:57:37.263] soft_als: iter 006, frobenious norm change 0.004 loss NA  \n",
            "INFO  [12:57:38.252] soft_als: iter 007, frobenious norm change 0.003 loss NA  \n",
            "INFO  [12:57:39.207] soft_als: iter 008, frobenious norm change 0.002 loss NA  \n",
            "INFO  [12:57:40.138] soft_als: iter 009, frobenious norm change 0.001 loss NA  \n",
            "INFO  [12:57:41.106] soft_als: iter 010, frobenious norm change 0.001 loss NA  \n",
            "INFO  [12:57:41.109] soft_impute: converged with tol 0.001000 after 10 iter \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgqRQI7pHosf"
      },
      "source": [
        "### KNN\n",
        "Let's now repeat the experiment on the KNN classified using LSA features instead of TF-IDF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXwzj58hUD0r"
      },
      "source": [
        "Prediction phase:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBATVZy5HoyP"
      },
      "source": [
        "knn_preds_lsa <- knn(train = train_lsa, test = test_lsa, cl = train$class, k=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5fku7vOUIwm"
      },
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "7fBZVyrPHudA",
        "outputId": "0dff2a76-541c-49c7-dcb4-a9dae1296443"
      },
      "source": [
        "cat(\"Confusion Matrix:\")\n",
        "ConfusionDF(y_pred = knn_preds_lsa, y_true = test$class)\n",
        "cat(\"\\nF1 score:\")\n",
        "F1_Score(y_pred = knn_preds_lsa, y_true = test$class)\n",
        "cat(\"\\nAccuracy:\")\n",
        "Accuracy(y_pred = knn_preds_lsa, y_true = test$class)\n",
        "cat(\"\\nPrecision:\")\n",
        "Precision(y_pred = knn_preds_lsa, y_true = test$class)\n",
        "cat(\"\\nRecall:\")\n",
        "Recall(y_pred = knn_preds_lsa, y_true = test$class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  y_true y_pred Freq\n",
              "1 ham    ham    1184\n",
              "2 spam   ham      15\n",
              "3 ham    spam     29\n",
              "4 spam   spam    166"
            ],
            "text/latex": "A data.frame: 4 × 3\n\\begin{tabular}{lll}\n y\\_true & y\\_pred & Freq\\\\\n <chr> & <chr> & <int>\\\\\n\\hline\n\t ham  & ham  & 1184\\\\\n\t spam & ham  &   15\\\\\n\t ham  & spam &   29\\\\\n\t spam & spam &  166\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 4 × 3\n\n| y_true &lt;chr&gt; | y_pred &lt;chr&gt; | Freq &lt;int&gt; |\n|---|---|---|\n| ham  | ham  | 1184 |\n| spam | ham  |   15 |\n| ham  | spam |   29 |\n| spam | spam |  166 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 4 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>y_true</th><th scope=col>y_pred</th><th scope=col>Freq</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>ham </td><td>ham </td><td>1184</td></tr>\n",
              "\t<tr><td>spam</td><td>ham </td><td>  15</td></tr>\n",
              "\t<tr><td>ham </td><td>spam</td><td>  29</td></tr>\n",
              "\t<tr><td>spam</td><td>spam</td><td> 166</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "F1 score:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9817579"
            ],
            "text/latex": "0.981757877280265",
            "text/markdown": "0.981757877280265",
            "text/html": [
              "0.981757877280265"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9684362"
            ],
            "text/latex": "0.968436154949785",
            "text/markdown": "0.968436154949785",
            "text/html": [
              "0.968436154949785"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Precision:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9874896"
            ],
            "text/latex": "0.987489574645538",
            "text/markdown": "0.987489574645538",
            "text/html": [
              "0.987489574645538"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Recall:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9760923"
            ],
            "text/latex": "0.976092333058533",
            "text/markdown": "0.976092333058533",
            "text/html": [
              "0.976092333058533"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVoa9pO5ULh8"
      },
      "source": [
        "It can be observed that the results are indeed better compared with the prediction done on KNN without LSA features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcj7Y4twK8tJ"
      },
      "source": [
        "#### Confidence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-a2pNt3iCmX",
        "outputId": "89ee2cee-152b-41c2-ff9c-eb5cdf164d2f"
      },
      "source": [
        "p_knn_lsa <- get_confidence_interval(confidence = 0.95, y_pred = knn_preds_lsa, y_true = test$class)\n",
        "cat(\"Confidence interval: \")\n",
        "cat(\"(\",p_knn_lsa$min,\", \",p_knn_lsa$max,\")\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confidence interval: ( 0.9578935 ,  0.9764042 )"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1SwdH0zVZnM"
      },
      "source": [
        "As expected, the confidence interval is higher as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aizMKSeVIM8i"
      },
      "source": [
        "### Logistic Regression\n",
        "Let's repeat the experiment with LSA feature with Logistic Regression as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZGFUr3AV_fz"
      },
      "source": [
        "Training phase:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOB0JejRINIW"
      },
      "source": [
        "binomial_model_lsa <- cv.glmnet(x = train_lsa, y = train$class, family = \"binomial\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPDLR_DFWCdx"
      },
      "source": [
        "Prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93nepYhaIXWt"
      },
      "source": [
        "binomial_probabilities_lsa <- predict(binomial_model_lsa, newx = test_lsa, type = \"response\")\n",
        "binomial_preds_lsa <- preds_to_class(binomial_probabilities_lsa)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqe1iAwnWFrA"
      },
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "fuxppPwyImKd",
        "outputId": "6ed6cd03-a706-4c71-fc07-73f4dc17048b"
      },
      "source": [
        "cat(\"Confusion Matrix:\")\n",
        "ConfusionDF(y_pred = binomial_preds_lsa, y_true = test$class)\n",
        "cat(\"\\nF1 score:\")\n",
        "F1_Score(y_pred = binomial_preds_lsa, y_true = test$class)\n",
        "cat(\"\\nAccuracy:\")\n",
        "Accuracy(y_pred = binomial_preds_lsa, y_true = test$class)\n",
        "cat(\"\\nPrecision:\")\n",
        "Precision(y_pred = binomial_preds_lsa, y_true = test$class)\n",
        "cat(\"\\nRecall:\")\n",
        "Recall(y_pred = binomial_preds_lsa, y_true = test$class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  y_true y_pred Freq\n",
              "1 ham    ham    1208\n",
              "2 spam   ham      23\n",
              "3 ham    spam      5\n",
              "4 spam   spam    158"
            ],
            "text/latex": "A data.frame: 4 × 3\n\\begin{tabular}{lll}\n y\\_true & y\\_pred & Freq\\\\\n <chr> & <chr> & <int>\\\\\n\\hline\n\t ham  & ham  & 1208\\\\\n\t spam & ham  &   23\\\\\n\t ham  & spam &    5\\\\\n\t spam & spam &  158\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 4 × 3\n\n| y_true &lt;chr&gt; | y_pred &lt;chr&gt; | Freq &lt;int&gt; |\n|---|---|---|\n| ham  | ham  | 1208 |\n| spam | ham  |   23 |\n| ham  | spam |    5 |\n| spam | spam |  158 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 4 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>y_true</th><th scope=col>y_pred</th><th scope=col>Freq</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>ham </td><td>ham </td><td>1208</td></tr>\n",
              "\t<tr><td>spam</td><td>ham </td><td>  23</td></tr>\n",
              "\t<tr><td>ham </td><td>spam</td><td>   5</td></tr>\n",
              "\t<tr><td>spam</td><td>spam</td><td> 158</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "F1 score:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9885434"
            ],
            "text/latex": "0.988543371522095",
            "text/markdown": "0.988543371522095",
            "text/html": [
              "0.988543371522095"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9799139"
            ],
            "text/latex": "0.979913916786227",
            "text/markdown": "0.979913916786227",
            "text/html": [
              "0.979913916786227"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Precision:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.981316"
            ],
            "text/latex": "0.981316003249391",
            "text/markdown": "0.981316003249391",
            "text/html": [
              "0.981316003249391"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Recall:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.995878"
            ],
            "text/latex": "0.995877988458368",
            "text/markdown": "0.995877988458368",
            "text/html": [
              "0.995877988458368"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMFxxzJFWHfJ"
      },
      "source": [
        "Also for the case of Linear Regression can be observed a general improvement of the measurements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLcmwYdrLRpI"
      },
      "source": [
        "#### Confidence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "favlUYObMtwm",
        "outputId": "e35b3c96-d2e8-4e52-ee63-70c984363a9c"
      },
      "source": [
        "p_bin_lsa <- get_confidence_interval(confidence = 0.95, y_pred = binomial_preds_lsa, y_true = test$class)\n",
        "cat(\"Confidence interval: \")\n",
        "cat(\"(\",p_bin_lsa$min,\", \",p_bin_lsa$max,\")\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confidence interval: ( 0.9711231 ,  0.986067 )"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD7BwnP7Wc1S"
      },
      "source": [
        "And the confidence interval improves as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYNlbsyN_XBa"
      },
      "source": [
        "### Comparing Models\n",
        "Let's now proceed with the comparation of the two model trained on LSA features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccEtWFMf_aen"
      },
      "source": [
        "pos_knn_lsa <- get_num_pos(knn_preds_lsa, test$class)\n",
        "pos_bin_lsa <- get_num_pos(binomial_preds_lsa, test$class)\n",
        "\n",
        "e_knn_lsa <- get_e(n_trials, pos_knn_lsa)\n",
        "e_bin_lsa <- get_e(n_trials, pos_bin_lsa)\n",
        "\n",
        "d_lsa <- get_d(e_knn_lsa, e_bin_lsa)\n",
        "var_t_lsa <- get_var_t(n_trials, e_knn_lsa, e_bin_lsa)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNq5yoj8_dxJ",
        "outputId": "6bde9c7e-2d51-4d87-f367-4cddfefc0833"
      },
      "source": [
        "Z_lsa <- compute_z(confidence = 0.95)\n",
        "dt_lsa <- get_dt(Z_lsa, d_lsa, var_t_lsa)\n",
        "\n",
        "cat(\"Confidence interval: \")\n",
        "cat(\"(\",dt_lsa$min,\", \",dt_lsa$max,\")\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confidence interval: ( -0.0002897761 ,  0.0232453 )"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zcifIgW_86B"
      },
      "source": [
        "The difference between the two models fed with TF-IDF features processed with LSA is negligible with a confidence level of $0.95$.<br>\n",
        "The minimum confidence level that makes the difference negligible can be found in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc1CFQknBOxT",
        "outputId": "5d1fbe36-66c1-47bd-afb9-fae75d4aed25"
      },
      "source": [
        "min_z_lsa = d_lsa/sqrt(var_t_lsa)\n",
        "cat(\"Z =\",min_z_lsa,\"\\n\")\n",
        "\n",
        "negligible_confidence_lsa <- compute_confidence(Z = min_z_lsa)\n",
        "cat(\"Negligible confidence level:\",negligible_confidence_lsa,\"\\n\")\n",
        "\n",
        "dt_negl_lsa <- get_dt(min_z_lsa, d_lsa, var_t_lsa)\n",
        "cat(\"Confidence interval: \")\n",
        "cat(\"(\",dt_negl_lsa$min,\", \",dt_negl_lsa$max,\")\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z = 1.9117 \n",
            "Negligible confidence level: 0.9440853 \n",
            "Confidence interval: ( 0 ,  0.02295552 )"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}